{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3350c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import pandas_datareader as web\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "# import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "import pandas\n",
    "# from pandas_datareader import data as pdr\n",
    "\n",
    "from pyathena import connect\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47413a0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, LSTM\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Set up connection parameters\n",
    "region_name = # change to your region\n",
    "aws_access_key_id = # Change Accordingly\n",
    "aws_secret_access_key = # Change Accordingly\n",
    "s3_staging_dir =#  Change Accordingly\n",
    "# Connect to Athena\n",
    "conn = connect(region_name=region_name,\n",
    "               aws_access_key_id=aws_access_key_id,\n",
    "               aws_secret_access_key=aws_secret_access_key,\n",
    "               s3_staging_dir=s3_staging_dir)\n",
    "\n",
    "# Execute a SQL query\n",
    "query = 'SELECT * FROM \"kafka-stock-market\".\"kafka_stock_analysis_aakash\" ORDER BY date'\n",
    "data = pd.read_sql(query, conn)\n",
    "\n",
    "# Print the results\n",
    "print(len(data))\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cc553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare Data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
    "print(scaled_data)\n",
    "\n",
    "prediction_days = 60\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "  x_train.append(scaled_data[x-prediction_days:x, 0])\n",
    "  y_train.append(scaled_data[x,0])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e409bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1)) # prediction of the next close\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0afab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t0/8mj1dc3j1wzdh4k57nbbcwg80000gn/T/ipykernel_21494/2242965143.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append([row_data], ignore_index=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'VarCharValue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m query_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResultSet\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRows\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     row_data \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVarCharValue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      9\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mappend([row_data], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Rename the columns based on the column names in the result set\u001b[39;00m\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m query_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResultSet\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRows\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 8\u001b[0m     row_data \u001b[38;5;241m=\u001b[39m [\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVarCharValue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      9\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mappend([row_data], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Rename the columns based on the column names in the result set\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'VarCharValue'"
     ]
    }
   ],
   "source": [
    "''' Test the model accuracy on existing data'''\n",
    "test_data = data.tail(60)\n",
    "\n",
    "actual_prices = test_data['close'].values\n",
    "\n",
    "total_dataset = pd.concat((data['close'], test_data['close']), axis=0)\n",
    "\n",
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values\n",
    "model_inputs = model_inputs.reshape(-1,1)\n",
    "model_inputs = scaler.transform(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a0fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyathena\n",
      "  Downloading pyathena-2.23.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from pyathena) (2023.3.0)\n",
      "Collecting botocore>=1.29.4\n",
      "  Downloading botocore-1.29.88-py3-none-any.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3>=1.26.4\n",
      "  Downloading boto3-1.26.88-py3-none-any.whl (134 kB)\n",
      "\u001b[K     |████████████████████████████████| 134 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=4.1.0 in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from pyathena) (8.0.1)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 32.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from boto3>=1.26.4->pyathena) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from botocore>=1.29.4->pyathena) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from botocore>=1.29.4->pyathena) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/aakgna/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.29.4->pyathena) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3, pyathena\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.59\n",
      "    Uninstalling botocore-1.27.59:\n",
      "      Successfully uninstalled botocore-1.27.59\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.5.0\n",
      "    Uninstalling s3transfer-0.5.0:\n",
      "      Successfully uninstalled s3transfer-0.5.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.21.32\n",
      "    Uninstalling boto3-1.21.32:\n",
      "      Successfully uninstalled boto3-1.21.32\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.88 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.26.88 botocore-1.29.88 pyathena-2.23.0 s3transfer-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "\n",
    "for x in range(prediction_days, len(model_inputs)):\n",
    "  x_test.append(model_inputs[x-prediction_days:x, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]))\n",
    "predicted_prices = model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a555653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakgna/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, date, open, high, low, close, adj close, volume, closeusd]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# plot the preductions\n",
    "company = \"Test\"\n",
    "plt.plot(actual_prices, color=\"black\", label=f\"Actual {company} Price\")\n",
    "plt.plot(predicted_prices, color=\"green\", label=f\"Predicted {company} Price\")\n",
    "plt.title(f\"{company} Share Price\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'{company} Share Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479aea1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mMinMaxScaler\u001b[49m(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(scaled_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict next day \n",
    "real_data = [model_inputs[len(model_inputs) + 1 - prediction_days:len(model_inputs+1), 0]]\n",
    "real_data = np.array(real_data)\n",
    "real_data = np.reshape(real_data, (real_data.shape[0], real_data.shape[1], 1))\n",
    "\n",
    "prediction = model.predict(real_data)\n",
    "prediction = scaler.inverse_transform(prediction)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0854e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
